{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install numpy\\n!pip install matplotlib\\n!pip install scipy\\n!pip install getdist\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run only if you have not installed the next libraries\n",
    "\"\"\"\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scipy\n",
    "!pip install getdist\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "#### - change acceptance probability\n",
    "#### - add loss\n",
    "#### - build neural network\n",
    "#### - modify leapfrog\n",
    "#### - function to class MH and HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate as sci\n",
    "import time\n",
    "from getdist import plots, MCSamples\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "dpi = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ab385f2bad54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# Este programa implementa Hamiltonian Markov Chain Monte Carlo. El núcleo utilizado se basa en Metropolis Hastings.\n",
    "\n",
    "class LeapFrog:\n",
    "    def __init__(self, l, e, dw, m, z, dat, sigma):\n",
    "        self.l = l\n",
    "        self.e = e\n",
    "        self.dw = dw\n",
    "        self.m = m\n",
    "        self.x = z\n",
    "        self.y = dat\n",
    "        self.sigma = sigma\n",
    "        self.dim = len(self.m)\n",
    "        self.nx = network()\n",
    "        self.nv = network()\n",
    "        self.nx.zero_grad()\n",
    "        self.nv.zero_grad()\n",
    "        \n",
    "    def solve(self, theta, n, M):        \n",
    "        qe = theta\n",
    "        while True:\n",
    "            vi = np.random.multivariate_normal(mean=np.zeros(self.dim), cov=np.diag(self.m))\n",
    "            ve = vi\n",
    "            self.H = []\n",
    "            self.X = []\n",
    "            self.V = []\n",
    "            self.X.append(theta)\n",
    "            self.V.append(ve)\n",
    "            self.nx.forward(torch.FloatTensor(np.concatenate((qe, ve, [np.cos(2*np.pi*n/M), np.sin(2*np.pi*n/M)]))))\n",
    "            self.nv.forward(torch.FloatTensor(np.concatenate((qe, ve, [np.cos(2*np.pi*n/M), np.sin(2*np.pi*n/M)]))))\n",
    "            self.qx, self.sx, self.tx = self.nx.get()\n",
    "            self.qv, self.sv, self.tv = self.nv.get()\n",
    "            \n",
    "            self.qx = self.qx.detach.numpy()\n",
    "            self.sx = self.sx.detach.numpy()\n",
    "            self.tx = self.tx.detach.numpy()\n",
    "            self.qv = self.qv.detach.numpy()\n",
    "            self.sv = self.sv.detach.numpy()\n",
    "            self.tv = self.tv.detach.numpy()\n",
    "            for i in range(self.l):\n",
    "                v = ve*np.exp(0.5*self.e*self.sv) - 0.5*self.e*(gradiente(self.dw, qe, self.x, self.y, self.sigma)*\n",
    "                                                                 np.exp(self.e*self.qv) + self.tv) # actualiza momento en e/2\n",
    "                qe = qe*np.exp(self.e*self.sx) + self.e*(ve*np.exp(self.e*self.qx) + self.tx)\n",
    "                if qe[0]<0:\n",
    "                    qe[0] = qe[0]*-1\n",
    "                    ve[0] = ve[0]*-1\n",
    "                if qe[1]<0:\n",
    "                    qe[1] = qe[1]*-1\n",
    "                    ve[1] = ve[1]*-1\n",
    "                if qe[2]>1/3:\n",
    "                    qe[2] = 1/3 - qe[2]\n",
    "                    ve[2] = ve[2]*-1\n",
    "                ve = ve*np.exp(0.5*self.e*self.sv) - 0.5*self.e*(gradiente(self.dw, qe, self.x, self.y, self.sigma)*\n",
    "                                                                 np.exp(self.e*self.qv) + self.tv)\n",
    "                self.V.append(ve)\n",
    "                self.X.append(qe)\n",
    "                if i + 1==self.l: \n",
    "                    i += 1\n",
    "                self.H.append(hamiltoniano(p=ve*self.m, dat=self.y, sigma=self.sigma, theta=theta, z=self.x, m=self.m))\n",
    "            if i==self.l: \n",
    "                break\n",
    "    \n",
    "    def get(self):\n",
    "        return np.array(self.X), np.array(self.V*self.m), np.array(self.H)\n",
    "\n",
    "def likelihood(mod, dat, sigma): # retorna escalar, log(L)\n",
    "    sig = np.diagonal(sigma)\n",
    "    L = -0.5*chi2(mod, dat, sigma)[0]  + np.sum(-0.5*np.log(2*np.pi*sig**2))\n",
    "    #pp = np.argwhere((a1==-np.inf))\n",
    "    #a1[pp] = 0\n",
    "    return L\n",
    "\n",
    "\n",
    "def chi2(mod, dat, sigma):\n",
    "    sig = np.diagonal(sigma)\n",
    "    AA = np.sum(((dat - mod)/sig)**2)\n",
    "    BB = np.sum((dat - mod)/sig**2)\t\n",
    "    CC = np.sum(1/sig**2)\n",
    "    chi = AA - (BB**2)/CC\n",
    "    return chi, BB/CC\n",
    "\n",
    "\n",
    "def prior(theta): # log(pi)\n",
    "    ct = 1\n",
    "    r = np.diag(np.ones(len(theta))*ct)\n",
    "    p = -0.5*np.log(np.linalg.det(2*np.pi*r)) - 0.5*theta.dot((np.linalg.inv(r)).dot(theta)) \n",
    "    return p\n",
    "\n",
    "\n",
    "def acepta_hmc(ec, ep, EC, EP, x, X):\n",
    "    alpha = min(- EP - EC + ep + ec, 0) # log(alpha)\n",
    "    u = np.log(np.random.uniform())\n",
    "    if u<alpha:\n",
    "        return X, EP, np.exp(alpha)\n",
    "    else:\n",
    "        return x, ep, np.exp(alpha)\n",
    "    \n",
    "    \n",
    "def acepta_mh(T1, pos1, T2, pos2, m1, m2):\n",
    "    alpha = min(pos2 - pos1, 0) # log(alpha)\n",
    "    u = np.log(np.random.uniform())\n",
    "    if u<alpha:\n",
    "        return T2, pos2, m2\n",
    "    else:\n",
    "        return T1, pos1, m1    \n",
    "\n",
    "\n",
    "def EHubble(theta, z): # parametro de hubble\n",
    "    om0 = theta[0]\n",
    "    ol = theta[1]\n",
    "    w = theta[2]\n",
    "    arg = om0*(1 + z)**3 + (1 - om0 - ol)*(1 + z)**2 + ol*(1 + z)**(3*(1 + w))\n",
    "    EE = np.sqrt(arg)\n",
    "    return EE, arg\n",
    "\n",
    "\n",
    "def modelo(theta,z): # modulo de la distancia teorico\n",
    "    om0 = theta[0]\n",
    "    ol = theta[1]\n",
    "    omega_k = 1 - om0 - ol\n",
    "    E = EHubble(theta, z)[0]\n",
    "    I = sci.cumtrapz(1/(E + 1e-300), z, initial=0)+z[0]*((1/(E + 1e-300))[0] + 1)/2 # estabilidad numerica\n",
    "    o_k_s = np.sqrt(abs(omega_k))\n",
    "    if omega_k==0:\n",
    "        dl = (1 + z)*I\n",
    "    elif omega_k<0:\n",
    "        dl = (1 + z)*np.sin(o_k_s*I)/(o_k_s + 1e-300) # estabilidad numerica\n",
    "    elif omega_k>0:\t\n",
    "        dl = (1 + z)*np.sinh(o_k_s*I)/(o_k_s + 1e-300) # estabilidad numerica\n",
    "    dist = 5*np.log10(dl + 1e-300) # estabilidad numerica\n",
    "    #f (-np.inf==dist).any(): \n",
    "    #    print(theta)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def tasa(tant, tpos):\n",
    "    l = len(tant)\n",
    "    if np.sum(tant==tpos)==l:\n",
    "        c = 0\n",
    "    else:\n",
    "        c = 1\n",
    "    return c\n",
    "\n",
    "\n",
    "def revisa(theta, z):\n",
    "    arg = EHubble(theta, z)[1]\n",
    "    bol = np.sum(arg<0)\n",
    "    print(bol)\n",
    "    if bol>0:\n",
    "        a = 0 # raiz imaginaria \n",
    "    else:\n",
    "        a = 1 # raiz real\n",
    "    return a\n",
    "\n",
    "\n",
    "def argmin2(t1, t2, t3, V): # busca en base a vector chi2 y devulve minimos de los parametros\n",
    "    amin = np.argmin(V)\n",
    "    return t1[amin], t2[amin], t3[amin]\n",
    "\n",
    "\n",
    "def revisa1(X):\n",
    "    x = X[0]\n",
    "    y = X[1]\n",
    "    z = X[2]\n",
    "    xlim = np.array([0, 1])\n",
    "    ylim = xlim\n",
    "    zlim = np.array([-np.inf, 1/3])\n",
    "    if xlim[0]<x<xlim[1] and ylim[0]<y<ylim[1] and zlim[0]<z<zlim[1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def potencial(dat, sigma, theta, z):\n",
    "    mod = modelo(theta, z)\n",
    "    u = - likelihood(mod, dat, sigma) - prior(theta) \n",
    "    return u\n",
    "\n",
    "\n",
    "def cinetica(p, m):\n",
    "    k = np.sum(p**2/2/m)\n",
    "    return k\n",
    "\n",
    "\n",
    "def hamiltoniano(p, dat, sigma, theta, z, m=1):\n",
    "    h = cinetica(p, m) + potencial(dat, sigma, theta, z)\n",
    "    return h\n",
    "\n",
    "\n",
    "def gradiente(dw, theta, z, dat, sigma):\n",
    "    tf = theta + dw\n",
    "    tb = theta - dw\n",
    "    grad = (potencial(dat, sigma, tf, z) - potencial(dat, sigma, tb, z))/(2*dw)\n",
    "    return grad\n",
    "\n",
    "\n",
    "def HMC(modelo, datos, ds, dg, N, L, params, q0, cov_mod, m, M, des=0.24):\n",
    "    \"\"\"\n",
    "    datos: X, F(X)\n",
    "    N: numero de iteraciones o epocas\n",
    "    M: tamaño del minibatch\n",
    "    params: ['p1', 'p2', ..., 'pn']\n",
    "    cov: matriz de covarianza de datos\n",
    "    \"\"\"\n",
    "    # Matrices de datos de la cadena\n",
    "    X = datos[0]\n",
    "    Y = datos[1]\n",
    "    chain = [] \n",
    "    post = [] \n",
    "    chi_2 = []\n",
    "    Ratio = []\n",
    "    acept = 0\n",
    "    mod1 = modelo(q0, X)\n",
    "    pos1 = potencial(Y, cov_mod, q0, X)\n",
    "    Chi1 = chi2(mod1, Y, cov_mod)[0]\n",
    "    chain.append(q0)\n",
    "    post.append(pos1)\n",
    "    chi_2.append(Chi1)\n",
    "    Ratio.append(100)\n",
    "    \n",
    "    leap = LeapFrog(l=L, e=ds, dw=dg, m=m, z=X, dat=Y, sigma=cov_mod)\n",
    "\n",
    "    Ti = time.time()\n",
    "    for i in range(N):\n",
    "        qo = np.random.uniform(low=[0,0,-5], high=[1, 1, 1/3], size=(M, 3))\n",
    "        Loss = 0\n",
    "        for j in range(M):\n",
    "            q = chain[j]\n",
    "            while True:\n",
    "                leap.solve(q, i, M)\n",
    "                Q, P, H = leap.get()\n",
    "                Q1 = Q[-1]\n",
    "                P1 = P[-1]\n",
    "                if revisa1(Q1):\n",
    "                    t = cinetica(P1[0], m)\n",
    "                    u = potencial(Y, cov_mod, q, X)\n",
    "                    T = cinetica(P1, m)\n",
    "                    U = potencial(Y, cov_mod, Q1, X)\n",
    "                    A = acepta_hmc(t, u, T, U, q, Q1)\n",
    "                    break\n",
    "            while True:\n",
    "                leap.solve(qo[j], i, M)\n",
    "                Qo, Po, Ho = leap.get()\n",
    "                Qo1 = Qo[-1]\n",
    "                Po1 = Po[-1]\n",
    "                if revisa1(Qo1):\n",
    "                    to = cinetica(Po1[0], m)\n",
    "                    uo = potencial(Y, cov_mod, qo[j], X)\n",
    "                    To = cinetica(Po1, m)\n",
    "                    Uo = potencial(Y, cov_mod, Qo1, X)\n",
    "                    Ao = acepta_hmc(to, uo, To, Uo, qo[j], Qo1)\n",
    "                    break\n",
    "            Loss += loss(q, Q1, qo[j], Qo1, A[2], Ao[2], par1=0.1, par2=0.1)\n",
    "            chain.append(A[0])\n",
    "            post.append(A[1])\n",
    "            mod1 = modelo(A[0], X)\n",
    "            Chi1 = chi2(mod1, Y, cov_mod)[0]\n",
    "            chi_2.append(Chi1)\n",
    "            # ratio de aceptacion\n",
    "            acept += tasa(chain[i], chain[i + 1]) \n",
    "            Ratio.append(acept/(M*i + j + 1)*100)                               \n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        Loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        print('Loss', Loss/M)         \n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "            print('ratio', Ratio[i])\n",
    "\n",
    "    Tf = time.time()\n",
    "    print('Tiempo cadena', np.around(Tf - Ti, 0), 's')\n",
    "\n",
    "    post = np.array(post)\n",
    "    chain = np.array(chain)\n",
    "    chi_2 = np.array(chi_2)\n",
    "    Ratio = np.array(Ratio)\n",
    "    H = np.array(H)\n",
    "\n",
    "    t1 = chain[:,0]\n",
    "    t2 = chain[:,1]\n",
    "    t3 = chain[:,2]\n",
    "\n",
    "    # busca argumento del minimo de chi2\n",
    "    t1m, t2m, t3m = np.around(argmin2(t1, t2, t3, chi_2),3)\n",
    "    mins = [t1m, t2m, t3m]\n",
    "    muestras = {}\n",
    "    for i in range(len(params)):\n",
    "        muestras[params[i]] = chain[:, i]\n",
    "    return muestras, Ratio, chi_2, post, mins\n",
    "\n",
    "\n",
    "def MH(modelo, datos, N, params, q0, cov_mod, cov_prop, des=0.24):\n",
    "    \"\"\"\n",
    "    datos: X, F(X)\n",
    "    params: ['p1', 'p2', ..., 'pn']\n",
    "    cov: matriz de covarianza de datos\n",
    "    \"\"\"\n",
    "    # Matrices de datos de la cadena\n",
    "    #pid = PID(kp=10, ki=10, kd=10, o_min=2, o_max=20)\n",
    "    T0 = q0\n",
    "    X = datos[0]\n",
    "    Y = datos[1]\n",
    "    chain = [] \n",
    "    post = [] \n",
    "    chi_2 = []\n",
    "    Ratio = []\n",
    "    mod = []\n",
    "    acept = 0\n",
    "    mod0 = modelo(T0, X)\n",
    "    chi0 = chi2(mod0, Y, cov_mod)[0]\n",
    "    pos0 = likelihood(mod0, Y, cov_mod) + prior(T0)\n",
    "    mod.append(mod0)\n",
    "    chain.append(T0)\n",
    "    post.append(pos0)\n",
    "    chi_2.append(chi0)\n",
    "    Ratio.append(100)\n",
    "\n",
    "    # pasos de cadena\n",
    "    Ti = time.time()\n",
    "    for i in range(N):\n",
    "        # revisa si se paso umbral de burn in\n",
    "        \"\"\"\t\n",
    "        if chi_2[i]<=580 and d==0 and o!=0:\n",
    "            covarianza = COV[o]\n",
    "            d = 1\n",
    "            print('actualizada')\n",
    "            print(covarianza)\n",
    "        \"\"\"\t\n",
    "        # selecciona ultimo elemento de la cadena\n",
    "        T0 = chain[i]\n",
    "        # itera hasta que encuentra un proposal valido\n",
    "        while True:\n",
    "            T1 = np.random.multivariate_normal(mean=T0, cov=cov_prop)\n",
    "            if revisa1(T1):\n",
    "                break\n",
    "        # selecciona ultimo modelo\n",
    "        mod0 = mod[i]\n",
    "        # calcula modelo con proposal\n",
    "        mod1 = modelo(T1, X)\n",
    "        # selecciona ultima dis. post.\n",
    "        pos0 = post[i]\n",
    "        # calcula nueva dist. post.\n",
    "        pos1 = likelihood(mod1, Y, cov_mod) + prior(T1)\n",
    "        # decision de aceptacion\n",
    "        A = acepta_mh(T0, pos0, T1, pos1, mod1, mod1)\n",
    "        # guarda la variable aceptada (puede ser la anterior o proposal)\n",
    "        chain.append(A[0])\n",
    "        post.append(A[1])\n",
    "        mod.append(A[2])\n",
    "        chi_2.append(chi2(A[2], Y, cov)[0])\n",
    "        # ratio de aceptacion\n",
    "        acept += tasa(chain[i], chain[i + 1]) \n",
    "        Ratio.append(acept/(i+1)*100)\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "            print('ratio', Ratio[i])\n",
    "\n",
    "    Tf = time.time()\n",
    "    print('Tiempo cadena', np.around(Tf - Ti, 0), 's')\n",
    "    \n",
    "    ratio = acept/N*100\n",
    "    print('ratio %', np.rint(ratio))\n",
    "\n",
    "    post = np.array(post)\n",
    "    chain = np.array(chain)\n",
    "    chi_2 = np.array(chi_2)\n",
    "    Ratio = np.array(Ratio)\n",
    "  \n",
    "    t1 = chain[:,0]\n",
    "    t2 = chain[:,1]\n",
    "    t3 = chain[:,2]\n",
    "\n",
    "    # busca argumento del minimo de chi2\n",
    "    t1m, t2m, t3m = np.around(argmin2(t1, t2, t3, chi_2),3)\n",
    "    mins = [t1m, t2m, t3m]\n",
    "    muestras = {}\n",
    "    for i in range(len(params)):\n",
    "        muestras[params[i]] = chain[:, i]\n",
    "    return muestras, Ratio, chi_2, post, mins\n",
    "\n",
    "\n",
    "def plot(arr1, arr2, keys, names, save=None):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True)\n",
    "    ax1.scatter(arr1[0][keys[0]], arr1[0][keys[1]], marker='.', alpha=0.1)\n",
    "    ax1.scatter(arr1[0][keys[0]][0], arr1[0][keys[1]][0], marker='x', color='red', alpha=1, label='inicio')\n",
    "    ax1.scatter(arr1[4][0], arr1[4][1], marker='o', color='black', alpha=1, label='best fit')\n",
    "    ax2.scatter(arr2[0][keys[0]], arr2[0][keys[1]], marker='.', alpha=0.1)\n",
    "    ax2.scatter(arr2[0][keys[0]][0], arr2[0][keys[1]][0], marker='x', color='red', alpha=1, label='inicio')\n",
    "    ax2.scatter(arr2[4][0], arr2[4][1], marker='o', color='black', alpha=1, label='best fit')\n",
    "    ax1.set_title('HMC')\n",
    "    ax2.set_title('MH')\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel(names[0])\n",
    "    ax2.set_ylabel(names[1])\n",
    "    ax1.set_ylabel(names[1])\n",
    "    if save!=None:\n",
    "        fig.savefig('muestras_'+keys[0]+'_'+keys[1], dpi=dpi)\n",
    "    return\n",
    "\n",
    "\n",
    "def autocorrelation(x, kmax=None):\n",
    "    N = len(x)\n",
    "    xmean = np.mean(x)\n",
    "    den = np.sum((x - xmean)*(x - xmean))    \n",
    "    if kmax==None:\n",
    "        kmax = int(N/2)\n",
    "    C = []\n",
    "    for i in range(kmax):\n",
    "        if i==0:\n",
    "            corr = 1\n",
    "        else:\n",
    "            corr = np.sum((x[i:] - xmean)*(x[:-i] - xmean))/den\n",
    "        C.append(corr)\n",
    "    return np.array(C)\n",
    "\n",
    "\n",
    "def delta(x1, x2):\n",
    "    return np.sum((x1 - x2)**2)\n",
    "\n",
    "def lam(x1, x2, ac, par1):\n",
    "    x = par1**2/delta(x1, x2)/ac\n",
    "    return x - 1/x\n",
    "\n",
    "def loss(x1, x2, y1, y2, ac1, ac2, par1, par2):\n",
    "    return lam(x1, x2, ac1, par1) + par2*lam(y1, y2, ac2, par1)\n",
    "\n",
    "\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(8, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fcq = nn.Linear(10, 3)\n",
    "        self.fcs = nn.Linear(10, 3)\n",
    "        self.fct = nn.Linear(10, 2)\n",
    "        self.ls = 1\n",
    "        self.lq = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        self.s = self.ls*F.tanh(self.fcs(h2))\n",
    "        self.q = self.lq*F.tanh(self.fcq(h2))\n",
    "        self.t = self.fct(h2)\n",
    "    \n",
    "    def get(self):\n",
    "        return self.q, self.s, self.t\n",
    "\n",
    "def train(net, dataset, optimizer, epochs, minibatches):\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        i = 0\n",
    "        for x, y in dataset.paquetes(minibatches):\n",
    "            # get the inputs\n",
    "            inputs = x\n",
    "            labels = y\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = cross_ent_loss(outputs, y, epsilon=1e-10) # criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            i += 1\n",
    "        print('Loss', running_loss/i)       \n",
    "    print('Finished Training')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved things directory\n",
    "direc = '/home/mauricio/Documents/Uni/Intro_2/' + 'gal.txt'\n",
    "\n",
    "# Carga de datos\n",
    "redshift = np.genfromtxt('gal.txt', usecols=(1))\n",
    "mu_obs = np.genfromtxt('gal.txt', usecols=(2)) # m - M\n",
    "cov = np.genfromtxt('gal.txt', usecols=(3))\n",
    "\n",
    "p = np.argsort(redshift)\n",
    "redshift = redshift[p]\n",
    "mu_obs = mu_obs[p]\n",
    "cov = cov[p]\n",
    "cov = np.diag(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuracion cadena\n",
    "\n",
    "# params\n",
    "labs = [r'$\\Omega_{m}$', r'$\\Omega_{\\Lambda}$', r'w']\n",
    "labs1 = [r'\\Omega_{m}', r'\\Omega_{\\Lambda}', r'w']\n",
    "\n",
    "M = -19.3182761161\n",
    "\n",
    "N = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metroplis-Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covarianza inicial\n",
    "cov_ini = np.diag(np.array([0.4, 1.125, 4])**2)*0.5e-2\n",
    "print(np.diag(cov_ini))\n",
    "q0 = np.random.uniform(low=[0,0,-5], high=[1, 1, 1/3], size=3)\n",
    "print('q0', q0)\n",
    "R_mh = MH(modelo, [redshift, mu_obs], N=N, params=['om', 'ol', 'w'], q0=q0, cov_mod=cov, cov_prop=cov_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian Monte Carlo\n",
    "##### Select L between 5 and 10 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 1e-2\n",
    "m = np.array([1, 1, 1])\n",
    "print('q0', q0)\n",
    "R_hmc = HMC(modelo, [redshift, mu_obs], ds=ds, dg=1e-6, N=N, L=8, params=['om', 'ol', 'w'], \n",
    "            q0=q0, cov_mod=cov, m=m, M=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [r'$\\Omega_{m}$', r'$\\Omega_{\\Lambda}$']\n",
    "keys = ['om', 'ol']\n",
    "plot(R_hmc, R_mh, keys, names, save='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [r'$\\Omega_{m}$', r'$\\omega$']\n",
    "keys = ['om', 'w']\n",
    "plot(R_hmc, R_mh, keys, names, save='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [r'$\\Omega_{\\Lambda}$', r'$\\omega$']\n",
    "keys = ['ol', 'w']\n",
    "plot(R_hmc, R_mh, keys, names, save='yes please')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 3\n",
    "names = [\"x%s\"%i for i in range(ndim)]\n",
    "labels = [\"x_%s\"%i for i in range(ndim)]\n",
    "t1 = R_hmc[0]['om']\n",
    "t2 = R_hmc[0]['ol']\n",
    "t3 = R_hmc[0]['w']\n",
    "samps = np.vstack((t1, t2, t3)).T\n",
    "samples = MCSamples(samples=samps, names=labs1, labels=labs1)\n",
    "\n",
    "#Triangle plot\n",
    "g = plots.getSubplotPlotter()\n",
    "samples.updateSettings({'contours': [0.68, 0.95, 0.99]})\n",
    "g.settings.num_plot_contours = 3\n",
    "g.triangle_plot([samples], filled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_hmc_om = autocorrelation(R_hmc[0]['om'])\n",
    "ac_mh_om = autocorrelation(R_mh[0]['om'])\n",
    "   \n",
    "plt.plot(ac_hmc_om, label='HMC')\n",
    "plt.plot(ac_mh_om, label='MH')\n",
    "plt.title('autocorrelation')\n",
    "plt.legend()\n",
    "plt.xlabel('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(np.array([[0, 0], [0, 1], [1, 0], [1, 1]]))\n",
    "Y = torch.LongTensor(np.array([0, 1, 1, 0]))\n",
    "\n",
    "C = 2\n",
    "dataset = BatchingDataset(X, Y, C=C)\n",
    "\n",
    "print('X', dataset.datos)\n",
    "print('clases', dataset.clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.zero_grad()\n",
    "print(net)\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, dataset, optimizer, epochs=1000, minibatches=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(1, 2, 0.1, 0.3, 0.9, 0.2, 1e-1, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = network()\n",
    "X = torch.randn(2, 8)\n",
    "n1.forward(X)\n",
    "print(n1.get())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
