{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate as sci\n",
    "import time\n",
    "from getdist import plots, MCSamples\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "ds = tf.contrib.distributions\n",
    "\n",
    "%matplotlib inline\n",
    "dpi = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved things directory\n",
    "direc = '/home/mauricio/Documents/Uni/Intro_2/' + 'gal.txt'\n",
    "\n",
    "# Carga de datos\n",
    "redshift = np.genfromtxt('gal.txt', usecols=(1))\n",
    "mu_obs = np.genfromtxt('gal.txt', usecols=(2)) # m - M\n",
    "cov = np.genfromtxt('gal.txt', usecols=(3))\n",
    "\n",
    "p = np.argsort(redshift)\n",
    "redshift = redshift[p].astype(np.float32)\n",
    "mu_obs = mu_obs[p]\n",
    "cov = cov[p]\n",
    "cov = np.diag(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def f1(theta, z, omk):\n",
    "    zc = np.copy(z)\n",
    "    zc = np.insert(zc, 0, 0)\n",
    "    dz = zc[1:] - zc[:-1]\n",
    "    E = EHubble(theta, z)[0]\n",
    "    I = tf.cumsum(dz/(E + 1e-300), axis=1)\n",
    "    o_k_s = tf.reshape(tf.sqrt(abs(omk)), [batch_size, 1])\n",
    "    return (1 + z)*tf.sinh(o_k_s*I)/(o_k_s + 1e-300)\n",
    "\n",
    "\n",
    "def f2(theta, z, omk):\n",
    "    zc = np.copy(z)\n",
    "    zc = np.insert(zc, 0, 0)\n",
    "    dz = zc[1:] - zc[:-1]\n",
    "    E = EHubble(theta, z)[0]\n",
    "    I = tf.cumsum(dz/(E + 1e-300), axis=1)\n",
    "    o_k_s = tf.reshape(tf.sqrt(abs(omk)), [batch_size, 1])\n",
    "    return (1 + z)*tf.sin(o_k_s*I)/(o_k_s + 1e-300)\n",
    "\n",
    "\n",
    "def f3(theta, z, omk):\n",
    "    zc = np.copy(z)\n",
    "    zc = np.insert(zc, 0, 0)\n",
    "    dz = zc[1:] - zc[:-1]\n",
    "    E = EHubble(theta, z)[0]\n",
    "    I = tf.cumsum(dz/(E + 1e-300), axis=1)\n",
    "    return (1 + z)*I\n",
    "\n",
    "\n",
    "def EHubble(theta, z): # parametro de hubble\n",
    "    \"\"\"\n",
    "    theta: parameter space state.\n",
    "    z: redshift.\n",
    "    bs: batch size.\n",
    "    \"\"\"\n",
    "    bs = batch_size\n",
    "    om0 = theta[:, 0]\n",
    "    ol = theta[:, 1]\n",
    "    w = theta[:, 2]\n",
    "    ts = tf.shape(theta)\n",
    "    zz = np.tile(z, (bs, 1))\n",
    "    arg = tf.reshape(om0, [ts[0], 1])*(1 + z)**3 + tf.reshape((1 - om0 - ol), [ts[0], 1])*(1 + z)**2 + tf.reshape(ol, [ts[0], 1])*(1 + z)**(3*(1 + tf.reshape(w, [ts[0], 1])))\n",
    "    EE = tf.sqrt(arg)\n",
    "    return EE, arg\n",
    "\n",
    "\n",
    "def modelo(theta, z):    \n",
    "    om0 = theta[:, 0]\n",
    "    ol = theta[:, 1]\n",
    "    w = theta[:, 2]    \n",
    "    omega_k = 1 - om0 - ol\n",
    "    sig = tf.sign(omega_k)\n",
    "    may = tf.reshape(1 + tf.sign(sig - 1), [batch_size, 1])\n",
    "    men = tf.reshape(1 - tf.abs(sig), [batch_size, 1])\n",
    "    eq = tf.reshape(1 - tf.sign(sig + 1), [batch_size, 1])    \n",
    "    dl = may*f1(theta, z, omega_k) + eq*f3(theta, z, omega_k) + men*f2(theta, z, omega_k)\n",
    "    # integral\n",
    "    dist = 5*tf.log(dl + 1e-300)/np.log(10)\n",
    "    return dist\n",
    "\n",
    "\n",
    "class potential:\n",
    "    def __init__(self, dat, sigma, z):\n",
    "        self.data = dat\n",
    "        self.cov = sigma\n",
    "        self.z = z\n",
    "    \n",
    "    def value(self, theta):\n",
    "        self.mod = modelo(theta, self.z)\n",
    "        self.u = - likelihood(self.mod, self.data, self.cov) #- prior(theta, ndim) \n",
    "        return self.u\n",
    "    \n",
    "    def grad(self, theta):\n",
    "        self.mod = modelo(theta, self.z)\n",
    "        self.u = - likelihood(self.mod, self.data, self.cov)\n",
    "        self.gradient = tf.gradients(self.u, theta)\n",
    "        return self.gradient\n",
    "\n",
    "\n",
    "def likelihood(mod, dat, sigma): # retorna escalar, log(L)\n",
    "    \"\"\"Log likelihood\n",
    "    mod: tf.tensor with model results\n",
    "    dat: numpy array of data\n",
    "    sigma: numpy array of covariance\"\"\"\n",
    "    sig = tf.cast(tf.diag_part(sigma), tf.float32)\n",
    "    L = -0.5*chi2(mod, dat, sigma)[0]  + tf.reduce_sum(-0.5*tf.log(2*np.pi*sig**2))\n",
    "    return L\n",
    "\n",
    "\n",
    "def chi2(mod, dat, sigma):\n",
    "    dat1 = np.tile(dat, (batch_size, 1))\n",
    "    sig = tf.cast(tf.diag_part(sigma), tf.float32)\n",
    "    sig1 = np.tile(sig, (batch_size, 1))\n",
    "    AA = tf.reduce_sum(tf.square((dat1 - mod)/sig))\n",
    "    BB = tf.reduce_sum((dat1 - mod)/tf.square(sig))\n",
    "    CC = tf.reduce_sum(1/tf.square(sig))\n",
    "    chi = AA - (BB**2)/CC\n",
    "    return chi, BB/CC\n",
    "\n",
    "\n",
    "def time_encodig(m, m_act):\n",
    "    arg = 2*np.pi*m_act/m\n",
    "    val = np.array([np.cos(arg), np.sin(arg)])\n",
    "    return tf.assign(t1, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prior:\n",
    "    def __init__(self, name, low=None, high=None, mean=None, cov=None):\n",
    "        if name=='uniform':\n",
    "            self.u = tf.distributions.Uniform(low=low, high=high)\n",
    "        elif name=='normal':\n",
    "            self.u = tf.contrib.distributions.MultivariateNormalFullCovariance(loc=mean, covariance_matrix=cov)\n",
    "    \n",
    "    def get_samples(self, n):\n",
    "        return self.u.sample(sample_shape=(n))\n",
    "    \n",
    "    def get_pdf(self, value):\n",
    "        return self.u.prob(value)\n",
    "    \n",
    "    def get_log_pdf(self, value):\n",
    "        return self.u.log_prob(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leapfrog:\n",
    "    def __init__(self, U, m, ndim, nnx, nnv, e, b):\n",
    "        \"\"\"\n",
    "        U: potential energy function\n",
    "        m: # of leapfrog steps\n",
    "        ndim: # of dimensions\n",
    "        nnx: neural network of x's\n",
    "        nnv: neural network of v's\n",
    "        e: leapfrog step parameter\n",
    "        b: batch size\n",
    "        \"\"\"\n",
    "        self.U = U\n",
    "        self.m = m\n",
    "        self.ndim = ndim\n",
    "        self.nnx = nnx\n",
    "        self.nnv = nnv\n",
    "        self.e = e\n",
    "        self.b = b\n",
    "        \n",
    "    def direction(self):\n",
    "        \"\"\"Samples a new direction\"\"\"\n",
    "        self.d = np.random.choice([-1, 1])\n",
    "        return\n",
    "        \n",
    "    def for_dyn(self):\n",
    "        \"\"\"One step of forward dynamics d=1.\n",
    "        x0: actual position in parameter space.\n",
    "        v0: actual velocity.\n",
    "        \"\"\"\n",
    "        # remember S, Q, T update in each sub iteration\n",
    "        \n",
    "        self.v = self.v*tf.exp(0.5*self.nnv.S*self.e) - 0.5*self.e*(self.U.grad(self.x)*tf.exp(self.nnv.Q*self.e) + self.nnv.T)\n",
    "        self.x = self.x*tf.exp(self.e*self.nnx.S) + self.e*(self.v*tf.exp(self.e*self.nnx.Q) + self.nnx.T)\n",
    "        self.x = tf.squeeze(self.x)\n",
    "        self.v = tf.squeeze(self.v)        \n",
    "        self.v = self.v*tf.exp(0.5*self.nnv.S*self.e) - 0.5*self.e*(self.U.grad(self.x)*tf.exp(self.nnv.Q*self.e) + self.nnv.T)\n",
    "        return\n",
    "    \n",
    "    def back_dyn(self):\n",
    "        \"\"\"One step of backward dynamics d=-1\n",
    "        x0: actual position in parameter space.\n",
    "        v0: actual velocity.\n",
    "        \"\"\"\n",
    "        self.v = self.v*tf.exp(- 0.5*self.nnv.S*self.e) + 0.5*self.e*(self.U.grad(self.x)*tf.exp(self.nnv.Q*self.e) + self.nnv.T)\n",
    "        self.x = self.x*tf.exp(- self.e*self.nnx.S) - self.e*(self.v*tf.exp(self.e*self.nnx.Q) + self.nnx.T)\n",
    "        self.x = tf.squeeze(self.x)\n",
    "        self.v = tf.squeeze(self.v) \n",
    "        self.v = self.v*tf.exp(- 0.5*self.nnv.S*self.e) + 0.5*self.e*(self.U.grad(self.x)*tf.exp(self.nnv.Q*self.e) + self.nnv.T)\n",
    "        return\n",
    "        \n",
    "    def dyn(self):\n",
    "        \"\"\"m steps dynamics\"\"\"\n",
    "        #self.direction()\n",
    "        for i in range(self.m):\n",
    "            #self.mask = np.random.choice([1, 0], size=(self.b, self.ndim), p=[0.5, 0.5])\n",
    "            #self.nmask = np.ones((self.b, self.ndim)) - self.mask\n",
    "            if self.d==1:\n",
    "                self.for_dyn()\n",
    "            elif self.d==-1:\n",
    "                self.back_dyn()\n",
    "        return\n",
    "        \n",
    "    def resample(self):\n",
    "        \"\"\"Resamples velocity and direction\"\"\"\n",
    "        self.v = tf.random_normal(shape=(self.b, self.ndim), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "        self.direction()\n",
    "        return\n",
    "    \n",
    "    def flip(self):\n",
    "        \"\"\"Flip direction\"\"\"\n",
    "        self.d *= -1       \n",
    "        return\n",
    "    \n",
    "    def sampling(self):\n",
    "        \"\"\"Sampling operation\"\"\"\n",
    "        self.direction()\n",
    "        self.dyn()\n",
    "        self.flip()\n",
    "        return\n",
    "    \n",
    "    def update_state(self, x0):\n",
    "        self.x = x0\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2HMC:\n",
    "    def __init__(self, U, prior, n, b, m, lr, sc, reg, lf, x0):\n",
    "        \"\"\"\n",
    "        U: energy function\n",
    "        prior: prior distribution\n",
    "        n: # iterations\n",
    "        b: batch size\n",
    "        m: leapfrog steps\n",
    "        lr: learning rate\n",
    "        sc: scale parameter\n",
    "        reg: regularization parameter\n",
    "        x0: initial position in parameter space\n",
    "        lf: leapfrog object\n",
    "        \"\"\"\n",
    "        self.U = U\n",
    "        self.prior = prior\n",
    "        self.n = n\n",
    "        self.b = b\n",
    "        self.m = m\n",
    "        self.lr = lr\n",
    "        self.sc = sc\n",
    "        self.reg = reg\n",
    "        self.init_samples = self.prior.get_samples(b)\n",
    "        self.lf = lf\n",
    "        self.X = x0 # ep\n",
    "        \n",
    "    def Run(self):\n",
    "        for i in range(self.n):\n",
    "            print(i)\n",
    "            self.xq = self.prior.get_samples(self.b) # from prior distribution eq\n",
    "            # first updates ep positions\n",
    "            self.lf.update_state(self.X) # now leapfrog knows the state to evolve\n",
    "            self.lf.resample()\n",
    "            self.lf.sampling()\n",
    "            print(self.lf.x)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, ndim, n1, n2, ls, lq):\n",
    "        \"\"\"\n",
    "        ndim: # of dimensions\n",
    "        n1: # of neurons of layer 1\n",
    "        ls: output parameter\n",
    "        lq: output parameter\n",
    "        \"\"\"\n",
    "        self.W1 = tf.Variable(tf.random_normal([ndim, n1]))\n",
    "        self.W2 = tf.Variable(tf.random_normal([ndim, n1]))\n",
    "        self.W3 = tf.Variable(tf.random_normal([2, n1])) # time encoding\n",
    "        self.W4 = tf.Variable(tf.random_normal([n1, n2]))\n",
    "        self.Ws = tf.Variable(tf.random_normal([n2, 1]))\n",
    "        self.Wq = tf.Variable(tf.random_normal([n2, 1]))\n",
    "        self.Wt = tf.Variable(tf.random_normal([n1, 1]))\n",
    "        self.b1 = tf.Variable(tf.random_normal([n1]))\n",
    "        self.b2 = tf.Variable(tf.random_normal([n2]))\n",
    "        self.bs = tf.Variable(tf.random_normal([ndim]))\n",
    "        self.bq = tf.Variable(tf.random_normal([ndim]))\n",
    "        self.bt = tf.Variable(tf.random_normal([ndim]))\n",
    "        self.ls = ls\n",
    "        self.lq = lq\n",
    "    \n",
    "    def model(self, x, v, t):\n",
    "        h1 = tf.matmul(x, self.W1) + tf.matmul(v, self.W2) + tf.matmul(t, self.W3) + self.b1\n",
    "        h1 = tf.nn.relu(h1)\n",
    "        h2 = tf.matmul(h1, self.W4) + self.b2\n",
    "        h2 = tf.nn.relu(h2)\n",
    "        self.S = tf.tanh(tf.matmul(h2, self.Ws) + self.bs)\n",
    "        self.Q = tf.tanh(tf.matmul(h2, self.Wq) + self.bq)\n",
    "        self.T = tf.matmul(h2, self.Wt) + self.bt\n",
    "    \n",
    "    \n",
    "    #loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    #train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = [0., 0., -6.]\n",
    "high = [1., 1., 1/3]\n",
    "global batch_size\n",
    "batch_size = 2\n",
    "\n",
    "x1 = np.array([[0.5, 0.4, -0.5], [0.5, 0.4, -0.5]])\n",
    "x1 = tf.convert_to_tensor(x1, dtype=tf.float32)\n",
    "\n",
    "v1 = np.array([[0.3, 0.4, -1.5], [0.3, 0.4, -1.5]])\n",
    "v1 = tf.convert_to_tensor(v1, dtype=tf.float32)\n",
    "\n",
    "t1 = np.zeros((2, 2))\n",
    "t1 = tf.convert_to_tensor(t1, dtype=tf.float32)\n",
    "\n",
    "a1 = np.array([1, 2, 3])\n",
    "a1 = tf.convert_to_tensor(a1, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot = potential(mu_obs, cov, redshift)\n",
    "pr = prior(name='uniform', low=low, high=high)\n",
    "mlpx = MLP(ndim=3, n1=10, n2=10, ls=1, lq=1)\n",
    "mlpv = MLP(ndim=3, n1=10, n2=10, ls=1, lq=1)\n",
    "mlpx.model(x1, v1, t1)\n",
    "mlpv.model(x1, v1, t1)\n",
    "lp = Leapfrog(U=pot, m=2, ndim=3, nnx=mlpx, nnv=mlpv, e=1e-3, b=batch_size)\n",
    "l2 = L2HMC(pot, pr, 2, batch_size, 2, 1e-3, 1e-1, 1e-1, lp, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Tensor(\"Squeeze_26:0\", shape=(2, 3), dtype=float32)\n",
      "1\n",
      "Tensor(\"Squeeze_30:0\", shape=(2, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-f6e0f9008c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1113\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \"\"\"\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' %\n\u001b[0;32m--> 237\u001b[0;31m                       (fetch, type(fetch)))\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument None has invalid type <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "L2 = l2.Run()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(L2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'X1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-1c6c9fa7947b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'X1'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(L2.X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
